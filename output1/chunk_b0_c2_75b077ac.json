{
  "id": "b0_c2_75b077ac",
  "content": "Image of a line graph titled \"20 Total Retrieved Documents (~4K tokens)\". The x-axis is \"Position of Document with the Answer\" with ticks from 1st to 20th. The y-axis is \"Accuracy\" from 55 to 75. Two lines are plotted: \"gpt-3.5-turbo-0613\" and \"gpt-3.5-turbo-0613 (closed-book)\". Both lines show a U-shaped curve, with accuracy being highest at the 1st and 20th positions and lowest in the middle positions (around 10th-15th). Figure 1: Changing the location of relevant information in this case, the position of the passage that answers an input question within the language model\u2019s input context results in a U-shaped performance curve\u2014models are better at using relevant information that occurs at the very beginning (primacy bias) or end of the input context (recency bias), and performance degrades significantly when models must access and use information located in the middle of its input context.",
  "heading_hierarchy": [
    "Lost in the Middle: How Language Models Use Long Contexts",
    "1 Introduction"
  ],
  "page_numbers": [
    1,
    2,
    3,
    4
  ],
  "continuation_flag": "False",
  "source_batch": 0,
  "metadata": {
    "position_in_batch": 2,
    "raw_length": 906,
    "heading_count": 2
  }
}