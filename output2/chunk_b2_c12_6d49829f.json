{
  "id": "b2_c12_6d49829f",
  "content": "Acknowledgments We would like to thank Luke Zettlemoyer, who served as our TACL action editor, and the the anonymous reviewers for their comments and feedback. We also thank Claude Levoe-Vey, Gendres, Megan Leszczynski, Dmytro Okhonko, Maithra Raghu, Eric Wallace and Sang Michael Xie for feedback and discussions that helped improve this work. Further, we are grateful to Sewon Min for her help with the AmbigQA dataset. This work was supported by the Stanford Center for Research on Foundation Models (CRFM), by OpenAI via an API credits grant to the Stanford CRFM, and by Anthropic via the Claude academic access program.",
  "heading_hierarchy": [
    "Lost in the Middle: How Language Models Use Long Contexts",
    "Acknowledgments"
  ],
  "page_numbers": [
    9,
    10,
    11,
    12
  ],
  "continuation_flag": "False",
  "source_batch": 2,
  "metadata": {
    "position_in_batch": 12,
    "raw_length": 625,
    "heading_count": 2
  }
}